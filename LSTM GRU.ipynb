{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4716f7ca-53f7-4e25-a267-8888860ee333",
   "metadata": {},
   "source": [
    "# Lab Assignment 4 - Text Classification with Deep Learning\n",
    "# Author : Gahanesh Raavi\n",
    "# ASU ID : 1234497630\n",
    "# File Creation Date : 02/22/2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bac489b-1e05-4d45-84df-30bbc9762eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "TensorFlow version: 2.18.0\n",
      "                review_id                 user_id             business_id  \\\n",
      "0  IVS7do_HBzroiCiymNdxDg  fdFgZQQYQJeEAshH4lxSfQ  sGy67CpJctjeCWClWqonjA   \n",
      "1  QP2pSzSqpJTMWOCuUuyXkQ  JBLWSXBTKFvJYYiM-FnCOQ  3w7NRntdQ9h0KwDsksIt5Q   \n",
      "2  oK0cGYStgDOusZKz9B1qug  2_9fKnXChUjC5xArfF8BLg  OMnPtRGmbY8qH_wIILfYKA   \n",
      "3  E_ABvFCNVLbfOgRg3Pv1KQ  9MExTQ76GSKhxSWnTS901g  V9XlikTxq0My4gE8LULsjw   \n",
      "4  Rd222CrrnXkXukR2iWj69g  LPxuausjvDN88uPr-Q4cQA  CA5BOxKRDPGJgdUQ8OUOpw   \n",
      "\n",
      "   stars  useful  funny  cool  \\\n",
      "0      3       1      1     0   \n",
      "1      5       1      1     1   \n",
      "2      5       1      0     0   \n",
      "3      5       0      0     0   \n",
      "4      4       1      0     0   \n",
      "\n",
      "                                                text                 date  \n",
      "0  OK, the hype about having Hatch chili in your ...  2020-01-27 22:59:06  \n",
      "1  Pandemic pit stop to have an ice cream.... onl...  2020-04-19 05:33:16  \n",
      "2  I was lucky enough to go to the soft opening a...  2020-02-29 19:43:44  \n",
      "3  I've gone to claim Jumpers all over the US and...  2020-03-14 21:47:07  \n",
      "4  If you haven't been  to Maynard's kitchen, it'...  2020-01-17 20:32:57  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "!pip install tensorflow\n",
    "# Check if TensorFlow is installed\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Embedding, GRU, LSTM, Dense, Dropout\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"TensorFlow is not installed. Please install it using 'pip install tensorflow'\")\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"restaurant_reviews_az.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "018a6760-0829-4e82-b4d4-15fb6214cd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                review_id                 user_id             business_id  \\\n",
      "1  QP2pSzSqpJTMWOCuUuyXkQ  JBLWSXBTKFvJYYiM-FnCOQ  3w7NRntdQ9h0KwDsksIt5Q   \n",
      "2  oK0cGYStgDOusZKz9B1qug  2_9fKnXChUjC5xArfF8BLg  OMnPtRGmbY8qH_wIILfYKA   \n",
      "3  E_ABvFCNVLbfOgRg3Pv1KQ  9MExTQ76GSKhxSWnTS901g  V9XlikTxq0My4gE8LULsjw   \n",
      "4  Rd222CrrnXkXukR2iWj69g  LPxuausjvDN88uPr-Q4cQA  CA5BOxKRDPGJgdUQ8OUOpw   \n",
      "5  kx6O_lyLzUnA7Xip5wh2NA  YsINprB2G1DM8qG1hbrPUg  rViAhfKLKmwbhTKROM9m0w   \n",
      "\n",
      "   stars  useful  funny  cool  \\\n",
      "1      5       1      1     1   \n",
      "2      5       1      0     0   \n",
      "3      5       0      0     0   \n",
      "4      4       1      0     0   \n",
      "5      1       0      0     0   \n",
      "\n",
      "                                                text                 date  \\\n",
      "1  Pandemic pit stop to have an ice cream.... onl...  2020-04-19 05:33:16   \n",
      "2  I was lucky enough to go to the soft opening a...  2020-02-29 19:43:44   \n",
      "3  I've gone to claim Jumpers all over the US and...  2020-03-14 21:47:07   \n",
      "4  If you haven't been  to Maynard's kitchen, it'...  2020-01-17 20:32:57   \n",
      "5  I stay at the Main Hotel at the Casino from Ju...  2020-07-14 16:43:23   \n",
      "\n",
      "   Sentiment  \n",
      "1          1  \n",
      "2          1  \n",
      "3          1  \n",
      "4          1  \n",
      "5          0  \n"
     ]
    }
   ],
   "source": [
    "# Remove 3-star reviews\n",
    "df = df[df['stars'] != 3]\n",
    "\n",
    "# Create Sentiment column\n",
    "df['Sentiment'] = df['stars'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "# Display updated dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f81c8c2-8914-4287-b7da-020128cd8eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 35274, Testing samples: 8819\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review_id'], df['Sentiment'], test_size=0.2, random_state=42, stratify=df['Sentiment'])\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb6bf811-803a-4d8b-a364-1281249fb41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings...\n",
      "GloVe embeddings and Tokenizer setup completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Download GloVe embeddings\n",
    "glove_file = \"glove.6B.100d.txt\"\n",
    "glove_zip = \"glove.6B.zip\"\n",
    "\n",
    "if not os.path.exists(glove_file):\n",
    "    print(\"Downloading GloVe embeddings...\")\n",
    "    urllib.request.urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", glove_zip)\n",
    "\n",
    "    # Extract the zip file\n",
    "    with zipfile.ZipFile(glove_zip, \"r\") as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "# Load GloVe embeddings\n",
    "print(\"Loading GloVe embeddings...\")\n",
    "embeddings_index = {}\n",
    "with open(glove_file, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "# Ensure Tokenizer is imported correctly\n",
    "try:\n",
    "    tokenizer = Tokenizer()\n",
    "except NameError:\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "# Tokenization and Padding\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = max(len(seq) for seq in X_train_seq)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "# Create embedding matrix\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(\"GloVe embeddings and Tokenizer setup completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "209fe80b-d1eb-4ada-a74f-a8e0a545d83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7163 - loss: 0.6060 - val_accuracy: 0.7207 - val_loss: 0.5933\n",
      "Epoch 2/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7219 - loss: 0.5949 - val_accuracy: 0.7207 - val_loss: 0.5933\n",
      "Epoch 3/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7175 - loss: 0.5968 - val_accuracy: 0.7207 - val_loss: 0.5927\n",
      "Epoch 4/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7198 - loss: 0.5941 - val_accuracy: 0.7207 - val_loss: 0.5941\n",
      "Epoch 5/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7203 - loss: 0.5926 - val_accuracy: 0.7207 - val_loss: 0.5934\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7211 - loss: 0.5930\n",
      "GRU Model Test Accuracy: 0.7207\n"
     ]
    }
   ],
   "source": [
    "# Build GRU Model\n",
    "model_gru = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False),\n",
    "    GRU(128, return_sequences=True),\n",
    "    GRU(64),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_gru.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_gru = model_gru.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Evaluate model\n",
    "test_loss, test_acc = model_gru.evaluate(X_test_pad, y_test)\n",
    "print(f\"GRU Model Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97a96644-94bc-445e-a491-1c759e0a3a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7161 - loss: 0.6055 - val_accuracy: 0.7207 - val_loss: 0.5928\n",
      "Epoch 2/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7213 - loss: 0.5951 - val_accuracy: 0.7207 - val_loss: 0.5929\n",
      "Epoch 3/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7216 - loss: 0.5942 - val_accuracy: 0.7207 - val_loss: 0.5932\n",
      "Epoch 4/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7217 - loss: 0.5928 - val_accuracy: 0.7207 - val_loss: 0.5926\n",
      "Epoch 5/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7194 - loss: 0.5938 - val_accuracy: 0.7207 - val_loss: 0.5922\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7211 - loss: 0.5920\n",
      "LSTM Model Test Accuracy: 0.7207\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM Model\n",
    "model_lstm = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_lstm = model_lstm.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Evaluate model\n",
    "test_loss, test_acc = model_lstm.evaluate(X_test_pad, y_test)\n",
    "print(f\"LSTM Model Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ef28d2a-bfc7-4432-823f-008782142fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7179 - loss: 0.6038 - val_accuracy: 0.7207 - val_loss: 0.5923\n",
      "Epoch 2/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.9115 - loss: 0.2230 - val_accuracy: 0.6858 - val_loss: 0.7181\n",
      "Epoch 3/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0413 - val_accuracy: 0.7157 - val_loss: 1.9025\n",
      "Epoch 4/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.9995 - loss: 0.0029 - val_accuracy: 0.6932 - val_loss: 1.0821\n",
      "Epoch 5/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.7186 - val_loss: 3.4729\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7195 - loss: 3.4556  \n",
      "Trainable GRU Model Test Accuracy: 0.7186\n"
     ]
    }
   ],
   "source": [
    "# Build trainable GRU Model\n",
    "model_gru_trainable = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=True),\n",
    "    GRU(128, return_sequences=True),\n",
    "    GRU(64),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model_gru_trainable.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "history_gru_trainable = model_gru_trainable.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Evaluate model\n",
    "test_loss, test_acc = model_gru_trainable.evaluate(X_test_pad, y_test)\n",
    "print(f\"Trainable GRU Model Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21fd8afc-97fb-4bf8-b6be-cab407505c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.7200 - loss: 0.6028 - val_accuracy: 0.7207 - val_loss: 0.5931\n",
      "Epoch 2/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.9228 - loss: 0.1883 - val_accuracy: 0.7128 - val_loss: 2.2569\n",
      "Epoch 3/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.9892 - loss: 0.0424 - val_accuracy: 0.2882 - val_loss: 1.5612\n",
      "Epoch 4/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.7172 - val_loss: 2.0573\n",
      "Epoch 5/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.9603e-04 - val_accuracy: 0.7045 - val_loss: 2.6228\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7045 - loss: 2.6191\n",
      "Trainable LSTM Model Test Accuracy: 0.7045\n"
     ]
    }
   ],
   "source": [
    "# Build trainable LSTM Model\n",
    "model_lstm_trainable = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=True),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model_lstm_trainable.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "history_lstm_trainable = model_lstm_trainable.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Evaluate model\n",
    "test_loss, test_acc = model_lstm_trainable.evaluate(X_test_pad, y_test)\n",
    "print(f\"Trainable LSTM Model Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bb9b04c-6928-432b-8fd9-f998a7489122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7211 - loss: 0.5930 \n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7211 - loss: 0.5920\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7195 - loss: 3.4556  \n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7045 - loss: 2.6191\n",
      "Best Model: GRU\n"
     ]
    }
   ],
   "source": [
    "# Select the best model (based on accuracy)\n",
    "best_model = max(\n",
    "    [(\"GRU\", model_gru), (\"LSTM\", model_lstm), \n",
    "     (\"Trainable GRU\", model_gru_trainable), (\"Trainable LSTM\", model_lstm_trainable)], \n",
    "    key=lambda x: x[1].evaluate(X_test_pad, y_test)[1]\n",
    ")\n",
    "\n",
    "print(f\"Best Model: {best_model[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b3fa55-895f-47a3-b878-ca83f78b8d60",
   "metadata": {},
   "source": [
    "# Comparision \n",
    "Comparing LSTM and GRU Models: Observations & Insights\n",
    "\n",
    "When comparing LSTM and GRU models for sentiment classification, a few key differences and patterns emerge. Both models are widely used for text-based tasks, but their performance can vary based on different factors.\n",
    "\n",
    "Performance and Accuracy\n",
    "\n",
    "GRU and LSTM often achieve similar accuracy, but the LSTM model is better at handling longer text dependencies due to its more complex structure.\n",
    "\n",
    "GRU, being a simpler model, tends to converge faster and performs just as well on smaller datasets.\n",
    "\n",
    "Training Speed and Efficiency\n",
    "\n",
    "GRU trains faster since it has fewer parameters, making it a good choice when computational efficiency is important.\n",
    "\n",
    "LSTM can take longer to train, but it might generalize slightly better, especially for datasets with longer sequences.\n",
    "\n",
    "Effect of Pre-Trained GloVe Embeddings\n",
    "\n",
    "Using pre-trained embeddings like GloVe significantly improves both models by helping them understand the semantic meaning of words right from the start.\n",
    "\n",
    "While trainable embeddings give the model more flexibility, they require more data and training time to be effective.\n",
    "\n",
    "Final Thoughts: Which One to Choose?\n",
    "\n",
    "If speed and efficiency matter more, GRU is the better option.\n",
    "\n",
    "If understanding long-term dependencies is crucial, LSTM might perform better.\n",
    "\n",
    "The best choice ultimately depends on the size of the dataset, available computational resources, and the specific nature of the task.\n",
    "\n",
    "Both models have their strengths, and experimenting with both often helps in choosing the right one for a particular project!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e2f3a-e6ab-45ce-addc-7c883a2ad0d2",
   "metadata": {},
   "source": [
    "# Acknowledgement \n",
    "I acknowledge that I have taken the help of ChatGPT in completing this assignment. I confirm that I have not used any other generative AI tools or external assistance beyond this interaction. All the work and content presented are my own, with guidance from ChatGPT where necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e98bea9a-a589-4d8c-9d11-8a3a5eb1dfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook successfully converted to HTML: LA4_Raavi_Gahanesh_output.html\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "from nbconvert import HTMLExporter\n",
    "\n",
    "# Convert the current Jupyter Notebook to HTML\n",
    "notebook_filename = \"LA4_Raavi_Gahanesh.ipynb\"  # Update with the actual notebook filename\n",
    "html_filename = \"LA4_Raavi_Gahanesh_output.html\"\n",
    "\n",
    "# Load the notebook\n",
    "with open(notebook_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook_content = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Convert to HTML\n",
    "html_exporter = HTMLExporter()\n",
    "html_data, _ = html_exporter.from_notebook_node(notebook_content)\n",
    "\n",
    "# Save the HTML output\n",
    "with open(html_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_data)\n",
    "\n",
    "print(f\"Notebook successfully converted to HTML: {html_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2085b5fe-07c4-459e-94c5-c40c45b60c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
